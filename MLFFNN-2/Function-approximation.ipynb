{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating functions using Sigmoid Perceptrons\n",
    "\n",
    "In Multi-layer Feed Forward neural networks, you can observe a new found capability of a perceptron to learn non-linearly separable data sets. You have witnessed that networks with 2 or more layers, that can learn a non-linear decision boundary.  \n",
    "\n",
    "Here, you will be presented with an example, which aims to show, a function can be approximated using the Sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, here is how a Sigmoid function looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sigmoid with Positive weights](Images/P-Sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us consider that we want to approximate the function below:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    f(x) = \n",
    "    \\begin{cases}\n",
    "        1 \\ \\ \\text{if } 4 \\le x \\le 6 \\\\\n",
    "        0 \\ \\ \\text{Otherwise}\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of $f(x)$ is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Function f](Images/f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a sigmoid function to approximate the function. Conside the below arrangement...\n",
    "Below is a sigmoid function represented in red, that has very large positive weights. Now, all the points, $x \\ge 4$ will be in the positive region of the sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Approximation-1](Images/approx1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We similarly make use of another sigmoid function with negative large weights to capture, all the points such that $x \\le 6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Approximation 2](Images/approx2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two perceptrons(sigmoids) are used to approximate the function $f(x)$. \n",
    "\n",
    "\n",
    "\n",
    "![Approximations](Images/approx3.png)\n",
    "\n",
    "\n",
    "\n",
    "But, this is not enough.\n",
    "\n",
    "One perceptron accepts all $x$ for which $x \\ge 4$ and another accepts all $x$ such that $x \\le 6$. We make use of a third perceptron that behaves as a logical **and** gate to comibine outputs from the above perceptrons to give us the final result that, wheather a point belongs to the region $[4, 6]$ or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture would be like so:\n",
    "    \n",
    "![Neural Network](Images/nn.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
